import sys
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import skimpy

import warnings
warnings.filterwarnings('ignore')

from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score, davies_bouldin_score
from sklearn.preprocessing import StandardScaler
from sklearn import set_config
from colorama import Style, Fore


pd.set_option('display.max_rows', 100)
set_config(transform_output = 'pandas')
pd.options.mode.chained_assignment = None
warnings.simplefilter(action='ignore', category=FutureWarning)

import os
for dirname, _, filenames in os.walk("C:/For Internships & Job Applications/personal project/Wine Clustering"):
    for filename in filenames:
        print(os.path.join(dirname, filename))


%matplotlib inline
from collections import Counter
from sklearn.cluster import KMeans





df = pd.read_csv("wine-clustering.csv")
df.head()


df.info()


print(f"{Style.BRIGHT}{Fore.BLUE} SHAPE")
print(f'{Style.BRIGHT}{Fore.BLUE} -> train: {Fore.GREEN} {df.shape}')

print(f"\n\n{Style.BRIGHT}{Fore.BLUE} NULL VALUES")
print(f"{Style.BRIGHT}{Fore.BLUE} -> Train: {Fore.GREEN} {df.isnull().any().any()}")


df.columns


skimpy.skim(df)





corr_matrix = df.corr()

plt.figure(figsize=(12, 8))
sns.heatmap(corr_matrix, annot=True,
            cmap='coolwarm', fmt='.2f')
plt.title("Correlation Matrix of Features")
plt.show()





numeric_to_drop = []
correlation_threshold = 0.7

for i in range(len(list(df.columns))-1):
    for j in range(i+1, len(list(df.columns))-1):
        if abs(corr_matrix.iloc[i, j]) > correlation_threshold:
            feat1, feat2 = list(df.columns)[i], list(df.columns)[j]

            corr1 = corr_matrix[feat1].abs().mean()
            corr2 = corr_matrix[feat2].abs().mean()
            numeric_to_drop.append(feat2 if corr1 > corr2 else feat1)

numeric_selected = [f for f in list(df.columns) if f not in set(numeric_to_drop)]
print("\nNumeric Feature Selection:")
print("Dropped numeric features:", list(set(numeric_to_drop)))
print("Selected numeric features:", numeric_selected)





silhouette_scores = []
davies_scores = []
inertias = []
numeric_selected = df.columns
scaler = StandardScaler()
scaled_df = scaler.fit(df[numeric_selected])

K = range(2, 11)

for k in K:
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(scaled_df)
    
    labels = kmeans.labels_
    
    silhouette_scores.append(silhouette_score(scaled_df, labels))
    davies_scores.append(davies_bouldin_score(scaled_df, labels))
    inertias.append(kmeans.inertia_)

plt.figure(figsize=(16, 10))

plt.subplot(2, 2, 1)
plt.plot(K, silhouette_scores, 'bo-')
plt.xlabel('Number of Clusters (k)')
plt.ylabel('Silhouette Score')
plt.title('Silhouette Score vs Number of Clusters')
plt.grid(True)

plt.subplot(2, 2, 2)
plt.plot(K, davies_scores, 'ro-')
plt.xlabel('Number of Clusters (k)')
plt.ylabel('Davies-Bouldin Index')
plt.title('Davies-Bouldin Index vs Number of Clusters')
plt.grid(True)

plt.subplot(2, 2, 3)
plt.plot(K, inertias, 'mo-')
plt.xlabel('Number of Clusters (k)')
plt.ylabel('Within-Cluster Sum of Squares (WCSS)')
plt.title('Elbow Curve')
plt.grid(True)

plt.tight_layout()
plt.show()

optimal_k_silhouette = K[np.argmax(silhouette_scores)]
optimal_k_davies = K[np.argmin(davies_scores)]  # Davies-Bouldin should be minimized

print(f"\nOptimal number of clusters based on Silhouette Score: {optimal_k_silhouette}")
print(f"Optimal number of clusters based on Davies-Bouldin Index: {optimal_k_davies}")





df_Kmeans = scaled_df.copy()
kmeans = KMeans(n_clusters=2)
kmeans.fit(df_Kmeans)


pred = kmeans.predict(df_Kmeans)
pred


plt.scatter(x=df_Kmeans.loc[:, ["Malic_Acid"]], 
            y=df_Kmeans.loc[:, ["Proline"]], c=pred)


silhouette_score(df_Kmeans, labels=kmeans.labels_, metric='cosine')



